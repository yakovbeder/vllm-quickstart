---
vllm:
  enabled: true
  resources:
    limits:
      cpu: 4
      memory: 16Gi
      nvidia.com/gpu: 1
    requests:
      cpu: 2
      memory: 8Gi
      nvidia.com/gpu: 1
  tolerations:
    - key: nvidia.com/gpu
      effect: NoSchedule
      operator: Exists


openwebui:
  enabled: true
  configuration:
    vllmEndpoints:
      - endpoint: 'http://{{ if eq .Release.Name "vllm" }}{{ .Release.Name }}{{ else }}{{ printf "%s-%s" .Release.Name "vllm" }}{{ end }}.{{ .Release.Namespace }}.svc:8000/v1'
        token: ""
